\section{Basics On Probability Theory}
This section is dedicated to a short review of basic concepts 
in probability theory.
\subsection{Probability Spaces and Random Variables}
\begin{definition}[$\sigma$-Algebra]
 Let $\Omega $  be a given set, then a $\sigma-$algebra $\mathcal{F}$ on $\Omega $ is a
 family of subsets of $\Omega $ s.t.
 \begin{enumerate}
   \item $\emptyset \in  \mathcal{F}$
   \item $F \in  \mathcal{F} \implies F^{c} \in  \mathcal{F} $
   \item If $A_{1},A_{2},\ldots \in \mathcal{F}$, then $  A = \bigcup_{j=1}^{\infty} A_j \in \mathcal{F}$.
 \end{enumerate}
\end{definition}
\begin{definition}[Measure Space]
 A tuple $(\Omega ,\mathcal{F})$  is called a measurable space. The elements of $\mathcal{F}$ are 
 called measurable sets. 
\end{definition}
\begin{definition}[Probability Measure]
 A probability measure $\P$ on $(\Omega ,\mathcal{F})$  is a function 
$ \P \ : \ \mathcal{F} \to [0,1]$ such that the following properties hold
 \begin{enumerate}
   \item $\P(\emptyset) = 0$ , $\P(\Omega ) = 1$
   \item If $A_{1},A_{2},\ldots \in \mathcal{F}$ s.t. $A_i \cap A_j = \emptyset \ \forall  i \neq j$,  then
    $\P(\bigcup_{j=1}^{\infty} A_j ) = \sum_{j=1}^{\infty} \P(A_j)$.
 \end{enumerate}
\end{definition}
\begin{definition}[Probability Space]
 The triple $(\Omega ,\mathcal{F},\P)$  is called a probability space. $F \in  \mathcal{F}$ is called an
 event. We say the probability space $(\Omega ,\mathcal{F},\P)$ is complete, if $\mathcal{F}$ contains all zero-measure sets i.e.
 if 
 \begin{align*}
  \inf \{\P(F) \ : \ F \in  \mathcal{F},G \subset  F\}  = 0
 .\end{align*}
 then $G \in  \mathcal{F}$ and $\P(G) = 0$.
\end{definition} 
\vskip5mm
Without loss of generality we use in this lecture $(\Omega ,\mathcal{F},\P)$
as complete probability space.
\begin{definition}[Almost Surely]
  If for some $F \in  \mathcal{F}$ it holds $\P(F) = 1$, then we say that $F$ happens with 
  probability 1 or happens almost surely (a.s.).
\end{definition}
\begin{remark}
 Let $\mathcal{U}$  be a family of subsets of $\Omega$, then there exists a smallest $\sigma-$algebra of 
 $\Omega$ which contains $\mathcal{H}$, it is denoted by $\mathcal{U}_{\mathcal{H}} = \bigcap \{\mathcal{H}: \mathcal{H} $ is a $\sigma-$ algebra of $\Omega$, and $\mathcal{U}\subset\mathcal{H}\}$.
 \end{remark}
\begin{example}
  The $\sigma-$algebra generated by a topology $\tau $ of $\Omega$ , $\mathcal{U}_{\tau } \triangleq \mathcal{B}$ is called 
  the Borel $\sigma-$algebra, the elements $B \in  \mathcal{B}$ are called Borel sets.
\end{example}
\begin{definition}[Measurable Functions]
 Let $(\Omega ,\mathcal{F},\P)$  be a probability space, a function 
$ Y \ : \ \Omega  \to \mathbb{R}^{d} $ 
 is called measurable if and only if $  Y^{-1}(B) \in  \mathcal{F} $ 
 holds for all $B \in  \mathcal{B}$ or equivalent for all $B \in  \tau $.
\end{definition}
\begin{example}
 Let $X : \Omega  \to  \mathbb{R}^{d} $  be a given function, then the $\sigma-$algebra $\mathcal{U}(X)$ generated by X is 
 \begin{align*}
  \mathcal{U}(X) = \{X^{-1}(B) \ : \ B \in  \mathcal{B} \}  
 .\end{align*}
\end{example}
\begin{lemma}[Doob-Dynkin]
 If $X,Y :  \Omega  \to \mathbb{R}^{d} $  are given functions, then $Y$ is $\mathcal{U}(X)$ measurable if and only if 
 there exists a Boreal measurable function $g \ : \ \mathbb{R}^{d} \to  \mathbb{R}^{d}  $ such that 
 \begin{align*}
  Y = g(x).
 .\end{align*}
\end{lemma}
\begin{exercise}
  Proof the above lemma
\end{exercise}

\vskip5mm
\begin{definition}[Random Variable]
 A random variable $X \ : \ \Omega  \to \mathbb{R}^{d} $  is a $\mathcal{F}-$measurable function.
 Every random variable induces a probability measure or $\mathbb{R}^{d} $ 
 \begin{align*}
  \mu_X(B) = \P(X^{-1}(B) ) \quad \forall B \in  \mathcal{B}
 .\end{align*}
This measure is called the distribution of X.
\end{definition}
\begin{remark}[$L^p$ spaces]
	Let $X : \Omega  \to  \mathbb{R}^{d} $  be a random variable and $p \in [1,\infty)$.
 With norm 
\begin{align*}
&\|X\|_p = \|X\|_{L^{p}(\P ) } = \left( \int_{\Omega} \abs{X(\omega )}^{p} d\P(\omega )  \right)^{\frac{1}{p}} , \mbox{ for } 1\leq p|\infty,\\
&\|X\|_{\infty} = \inf \{N \in  \mathbb{R} : \abs{X(\omega )} \le  N \text{ a.s.}\}  ,\mbox{ for } p=\infty
,\end{align*}
it can be shown that the space $ L^{p}(\Omega ) = \{X \ : \ \Omega  \to  \mathbb{R}^{d}   |  \|X\|_p \le \infty \}    $ is a Banach space.
\end{remark}
\begin{remark}
	If $p=2$ then $L^{2}(\P) $ is a Hilbert space with inner product 
	\begin{align*}
	\braket{X,Y} = \E[X(\omega )*Y(\Omega )] = \int_{\Omega }X(\omega )*Y(\omega )d\P(\omega )
	.\end{align*}
\end{remark}
\begin{definition}[Expectation and Variance]\hspace{1cm}\\
 Let $X$ be a random variable, if 
$  \int_{\Omega } \abs{X(\omega )}d\P(\omega ) < \infty$,
 then 
 \begin{align*}
   \E[X] = \int_{\Omega } X(\omega ) d\P(\omega ) =  \int_{\mathbb{R}^{d} }x d\mu_X(x)
 \end{align*}
 is called the expectation of $X$ (w.r.t. $\P$);
 \begin{align*}
   \V[X] = \int_{\Omega } \abs{X - \E[X]}^2 d\P(\omega )
 \end{align*}
 is called variance and the simple relation holds
 \begin{align*}
   \V[X] = \E[\abs{X-\E[X]}^2] = \E[\abs{X}^2] - \E[X]^2
 .\end{align*}
\end{definition}
\begin{remark}
 If $f : \mathbb{R}^{d} \to  \mathbb{R} $ is measurable and $ \int_{\Omega } \abs{f(X(\omega ))} d\P(\Omega ) <\infty$, 
 then it holds
 \begin{align*}
   \E[f(X)] = \int_{\Omega }f(X(\omega ))d\P(\omega ) = \int_{\mathbb{R}^{d} }f(x) d\mu_X(x)
 .\end{align*}
\end{remark}

\begin{definition}[Distribution Functions]
 Note for $x,y \in  \mathbb{R}^{d} $  we write $x\le y$ if $x_i \le  y_i$ for $\forall i$
 \begin{enumerate}
   \item $X: (\Omega ,\mathcal{F},\P) \to \mathbb{R}^{d} $ is a random variable, its distribution function $F_x : \mathbb{R}^{d} \to [0,1] $
     is defined by 
     \begin{align*}
      F_X(x) = \P(X\le x) \quad x \in  \mathbb{R}^{d} 
     .\end{align*}
    \item If $X_{1},\ldots ,X_m : \Omega \to \mathbb{R}^{d} $ are random variables, then their joint distribution function is
      \begin{align*}
        F_{X_{1},\ldots ,X_m} &: (\mathbb{R}^{d} )^m \to [0,1]\\
        F_{X_{1},\ldots ,X_m} &= \P(X_{1}\le x_{1},\ldots ,X_m\le x_m) \quad \forall x_i \in \mathbb{R}^{d} 
      .\end{align*}
 \end{enumerate}
\end{definition}
\begin{definition}[Density Function of random variables]
 If there exists a non-negative function $f(x) \in  L^{1}(\mathbb{R}^{d} ; \mathbb{R} ) $   such that 
 \begin{align*}
   F(x) = \int_{-\infty}^{x_{1}}  \ldots \int_{-\infty}^{x_d} f(y) dy \quad y = (y_{1},\ldots ,y_d)
 .\end{align*}
 then f is called the density function of $X$ and 
 \begin{align*}
  \P(X^{-1}(B) ) = \int_B f(x) dx \quad \forall  B \in  \mathcal{B}
 .\end{align*}
\end{definition}
\begin{example}
 Let $X$ be a random variable with density function 
 \begin{align*}
 f(x) = \frac{1}{\sqrt{2\pi \sigma ^2}}e^{-\frac{\abs{x-m}^2}{2\sigma ^2}}, \quad x \in  \mathbb{R},
 \end{align*}
 then we say that $X$ has a Gaussian (or Normal) distribution with mean $m$ and variance $\sigma^2$. In this case, we use the notation $  X \sim \mathcal{N}(m,\sigma^2)$.
 Obviously 
 \begin{align*}
   \int_{\mathbb{R}} xf(x) dx = m \quad \text{ and } \quad \int_{\mathbb{R}}\abs{x-m}^2f(x) dx = \sigma^2
  .\end{align*}
\end{example}
\begin{definition}[Independent Events]
  Events $A_{1},\ldots ,A_{n} \in  \mathcal{F}$ are called independent if $\forall 1 \le k_{1} < \ldots  < k_m \le  n$ it holds 
  \begin{align*}
    \P(A_{k_{1}}\cap A_{k_2} \cap \ldots \cap A_{k_m} )=\P(A_{k_{1}})\P(A_{k_{2}})\ldots \P(A_{k_m})
  .\end{align*}
\end{definition}
\begin{definition}[Independent $\sigma-$Algebra]
 Let $\mathcal{F}_j \subset  \mathcal{F}$   be $\sigma-$algebras for $j=1,2,\ldots $. Then we say $\mathcal{F}_j$ are independent if 
 for $\forall 1 \le k_{1}<k_{2}<\ldots <k_m$ and $\forall A_{k_j} \in  \mathcal{F}_{k_j}$ it holds
 \begin{align*}
  \P(A_{k_{1}}\cap A_{k_2} \cap \ldots \cap A_{k_m} )=\P(A_{k_{1}})\P(A_{k_{2}})\ldots \P(A_{k_m})
 .\end{align*}
\end{definition}
\begin{definition}[Independent Random Variables]
 We say random variables $X_{1},\ldots ,X_m \ : \ \Omega  \to \mathbb{R}^{d} $  are independent if 
 for $\forall  B_{1},\ldots ,B_{m} \subset  \mathcal{B}$ in $\mathbb{R}^{d} $ it holds 
 \begin{align*}
   \P(X_{j_{1}}\in B_{j_{1}},\ldots, X_{j_k}\in B_{j_k} ) = \P(X_{j_{1}} \in  B_{j_{1}})\ldots \P(X_{j_k} \in  B_{j_k})
 .\end{align*}
 which is equivalent to proving that $\mathcal{U}(X_{1}),\ldots ,\mathcal{U}(X_k)$ are independent
\end{definition}
\begin{theorem}
 $X_{1},\ldots ,X_m \ : \ \Omega  \to \mathbb{R}^{d} $ are independent if and only if 
 \begin{align*}
   F_{X_{1},\ldots ,X_m}(x_{1},\ldots ,x_m) =F_{X_{1}}(x_{1})\ldots F_{x_m}(x_m) \quad \forall  x_i \in \mathbb{R}^{d} 
 .\end{align*}
\end{theorem}

\begin{theorem}
  If $X_{1},\ldots ,X_m \ : \ \Omega  \to \mathbb{R} $ are independent and $\E[\abs{X_i}] < \infty$ then 
  \begin{align*}
    \E[\abs{X_{1},\ldots ,X_m}]<\infty
  .\end{align*}
  and 
  \begin{align*}
    \E[X_{1}\ldots X_m] = \E[X_{1}]\ldots \E[X_m]
  .\end{align*}
\end{theorem}
\begin{theorem}
  $X_{1},\ldots ,X_m \ : \ \Omega  \to \mathbb{R} $ are independent and $\V[X_i] <\infty$ then 
  \begin{align*}
    \V[X_{1} + \ldots  + X_m] = \V[X_{1}] + \ldots  + \V[X_m]
  .\end{align*}
\end{theorem}
\begin{exercise}
 Proof the above theorems
\end{exercise}
\subsection{Borel Cantelli}
\begin{definition}
 Let $A_{1},\ldots ,A_m,\ldots \in \mathcal{F}$, the set 
 \begin{align*}
   \bigcap_{n=1}^{\infty}\bigcup_{m=n}^{\infty} A_m = \{\omega \in \Omega  \ : \ \omega  \text{ belongs to infinite many } A_{m}\text{'s}\}  
 .\end{align*}
 is called $A_m$ infinitely often or $A_m$ i.o.
\end{definition}
\begin{lemma}[Borel Cantelli]\label{borel_cantelli}
 If $\sum_{m=1}^{\infty} \P(A_m) < \infty  $,  then $\P(A_m \text{ i.o. }) = 0$
\end{lemma}
\begin{proof}
 By definition we have 
 \begin{align*}
   \P(A_m \text{ i.o. }) \le  \P(\bigcup_{m=n}^{\infty} ) \le \sum_{m=n}^{\infty} \P(A_m)  \xrightarrow{m\to \infty} 0
 .\end{align*}
\end{proof}
\begin{definition}[Convergence in Probability]
  We say a sequence of random variables $(X_k)_{k=1}^{\infty} $  converges in probability to $X$ if 
  $\forall  \epsilon > 0$ it holds
  \begin{align*}
    \lim_{k\to \infty} \P(\abs{X_k - X} > \epsilon ) = 0 
  .\end{align*}
\end{definition}
\begin{theorem}[Application of Borel Cantelli]
 If $X_k \to  X$  in probability, then there exists 
 a subsequence $(X_{k_j})_{j=1}^{\infty} $ such that 
 \begin{align*}
   X_{k_j}(\omega ) \to X(\omega ) \text{ for almost surely } \omega \in  \Omega 
 .\end{align*}
 This means that $\P(\abs{X_{k_j}-X}\to 0) = 1$.
\end{theorem}
\begin{proof}
  Due to the convergence in probability, for each $j$, there exists $k_j$ with $k_j>k_{j-1}$ such that
  \begin{align*}
    \P(\abs{X_{k_j} - X} > \frac{1}{j}) \le \frac{1}{j^2}
  ,\end{align*}
  which implies that
  \begin{align*}
    \sum_{j=1}^{\infty} \P(\abs{X_{k_j}-X} > \frac{1}{j}) = \sum_{j=1}^{\infty} \frac{1}{j^2}   < \infty
  .\end{align*}
  Let $A_j = \{\omega  \ : \ \abs{X_{k_j}-X} > \frac{1}{j}\}  $, then by \nameref{borel_cantelli} we have $\P(A_j\text{ i.o.}) = 0$. This means for almost surely $\omega  \in  \Omega$, there exists a $J\in\N$ such that $\forall  j>J$,
  it holds 
  \begin{align*}
    \abs{X_{k_j}(\omega ) - X(\omega )} \le  \frac{1}{j}
  .\end{align*}
\end{proof}
\subsection{Strong Law of Large Numbers}
\begin{definition}
 A sequence of random variables $X_{1},\ldots ,X_n$  is called identically distributed if 
 \begin{align*}
   F_{X_{1}}(x)= F_{X_{2}}(x) = \ldots  = F_{X_n}(x) \quad \forall x \in  \mathbb{R}^{d}  
 .\end{align*}
 If additionally $X_{1},\ldots ,X_n$ are independent then we say they are identically-independent-distributed i.i.d.
\end{definition}
\begin{theorem}[Strong Law Of Large Numbers]
 Let $X_{1},\ldots ,X_N$  be a sequence of i.i.d integrable random variables on the same probability
 space $(\Omega ,\mathcal{F},\P)$ then 
 \begin{align*}
   \P(\lim_{N \to  \infty} \frac{X_1 + \ldots  + X_N}{N} = \E[X_i]) = 1
 .\end{align*}
 where $\E[X_i] = \E[X_j]$.
\end{theorem}
\begin{proof}
  Suppose for simplicity $\E[X_i^{4} ] < \infty$  for $\forall  i = 1,2,\ldots $.
  Then without loss of generality we may assume $\E[X_i] = 0$ otherwise we use $X_i - \E[X_i]$ as our new sequence.
  Consider 
  \begin{align*}
    \E[(\sum_{i=1}^{N} X_i )^{4} ] = \sum_{i,j,k,l}\E[X_iX_jX_kX_l]
  .\end{align*}
  If $i \neq j ,k,l$ then because of independence it follows that 
  \begin{align*}
    \E[X_iX_jX_kX_l] = \E[X_i]\E[X_jX_kX_l] = 0
  .\end{align*}
  Then 
  \begin{align*}
    \E[(\sum_{i=1}^{N}X_i )^{4} ] &= \sum_{i=1}^{N}\E[X_i^{4} ]  + 3 \sum_{i\neq j}\E[X_i^2X_j^2] \\
                                  &= N\E[X_{1}^{4} ] + 3(N^2-N)\E[X_{1}^2]^2 \\
                                  &\le  N^2C
  .\end{align*}
  Therefore for fixed $\epsilon > 0$
  \begin{align*}
    \P(\abs{\frac{1}{N} \sum_{i=1}^{N}X_i } \ge \epsilon) &= \P(\abs{\sum_{i=1}^{N}X_i }^{4}  \ge (\epsilon N)^{4} )\\
                                                          &\myS{Mrkv.}{\le} \frac{1}{(\epsilon N)^{4} } \E[\abs{\sum_{i=1}^{N} X_i }^{4} ]\\
                                                          &\le  \frac{C}{\epsilon^4}\frac{1}{N^2}
  .\end{align*}
  Then by \nameref{borel_cantelli} we get 
  \begin{align*}
    \P(\abs{\frac{1}{N} \sum_{i=1}^{N} X_i } \ge  \epsilon \text{ i.o.}) = 0
  .\end{align*}
  because 
  \begin{align*}
    \sum_{N=1}^{\infty} \P(A_N)  = \sum_{N=1}^{\infty} \frac{C}{\epsilon^4}\frac{1}{N^2}  < \infty
  .\end{align*}
  where  
  \begin{align*}
    A_N = \{\omega  \in  \Omega  \ : \ \abs{\frac{1}{N}\sum_{i=1}^{N}X_i } \ge  \epsilon\}  
  .\end{align*}
  Now we take $\epsilon = \frac{1}{k}$ then the above gives 
  \begin{align*}
    \lim_{N\to \infty} \sup \frac{1}{N} \sum_{i=1}^{N}  X_i(\omega ) \le \frac{1}{k}
  .\end{align*}
  holds except for $\omega  \in  B_k$ with $\P(B_k) = 0$. Let $B = \bigcup_{k=1}^{\infty} B_k $ then $\P(B) = 0$ and
  \begin{align*}
    \lim_{N \to \infty} \frac{1}{N} \sum_{i=1}^{N} X_i(\omega ) = 0  \text{ a.s.}
  .\end{align*}
\end{proof}
\subsection{Conditional Expectation}
We use in this part $(\Omega ,\mathcal{F},\P)$  as the probability space.
\begin{definition}
  Let $Y$ be random variable, then $\E[X|  Y] $ is defined as a $\mathcal{U}(Y)-$measurable random variable
  s.t for $\forall  A \in \mathcal{U}(Y)$ it holds 
  \begin{align*}
    \int_A X d\P = \int_A \E[X|Y] d\P
  .\end{align*}
\end{definition}
\begin{definition}
 Let  $\mathcal{ U} \subset  \mathcal{F}$ be a $\sigma-$algebra,
 if $X  : \Omega  \to  \mathbb{R}^{d} $ is an integrable random variable then $\E[X |\mathcal{U}]$  is
 defined as a random variable on $\Omega$ s.t. $\E[X | \mathcal{U}]$ is $\mathcal{U}-$measurable and for $A \in  \mathcal{U}$
 \begin{align*}
   \int_A X d\P  = \int_A \E[X | \mathcal{U}] d \P
 .\end{align*}
\end{definition}
\begin{exercise}
 Proof the following equalities  
 \begin{enumerate}
   \item $\E[X|Y] = \E[X | \mathcal{U}(Y)]$
   \item $\E[\E[X|\mathcal{U}]] = \E[X]$
   \item $\E[X] = \E[X | \mathcal{W}]$, where $\mathcal{W} = \{\emptyset,\Omega \}  $
 \end{enumerate}
\end{exercise}
\begin{remark}
 One can define the conditional probability similarly. Let $\mathcal{V} \subset  \mathcal{U}$  be a $\sigma-$algebra 
 then for $A \in  \mathcal{U}$ the conditional probability is defined as follows
 \begin{align*}
   \P(A | \mathcal{V}) = \E[\cha_A | \mathcal{V}]
 ,\end{align*}
where $\cha_A$ is the indication function of set $A$.
\end{remark}
\begin{theorem}
 Let $X$ be an integrable random variable, then for all $\sigma-$algebras $\mathcal{U} \subset  \mathcal{F}$  the 
 conditional expectation $\E[X | \mathcal{U}]$ exists and is unique up to $\mathcal{U}-$measurable sets of probability
 zero.
\end{theorem}
\begin{proof}
 Omit 
\end{proof}
\begin{theorem}[Properties Of Conditional Expectation]\hspace{1mm}\\
	
 \begin{enumerate}
   \item If $X$ is $\mathcal{U}-$measurable then $\E[X|\mathcal{U}] = X$ a.s.
   \item $\E[aX + bY|\mathcal{U}] = a\E[X|\mathcal{U}] + b \E[Y|\mathcal{U}]$
   \item If $X$ is $\mathcal{U}-$measurable and $XY$ is integrable then 
     \begin{align*}
       \E[XY|\mathcal{U}] = X \E[Y|\mathcal{U}]
     .\end{align*}
   \item If $X$ is independent of $\mathcal{U}$ then $\E[X|\mathcal{U}] = \E[X]$ a.s.
   \item If $\mathcal{W} \subset  \mathcal{U}$ are two $\sigma-$algebras then 
     \begin{align*}
       \E[X|\mathcal{W}] = \E[\E[X|\mathcal{U}]|\mathcal{W}] = \E[\E[X|\mathcal{W}]|\mathcal{U}] \text{ a.s.}
     \end{align*}
   \item If $X\le Y$ a.s. then $\E[X|\mathcal{U}] \le \E[Y|\mathcal{U}]$  a.s.
 \end{enumerate} 
\end{theorem}
\begin{exercise}
 Proof the above properties  
\end{exercise}
\begin{lemma}[Conditional Jensen's Inequality]
  Suppose $\phi  : \mathbb{R}\to \mathbb{R}$ is convex and $\E[\phi(x)] < \infty$, then
  \begin{align*}
    \phi(\E[X|\mathcal{U}]) \le \E[\phi(X)|\mathcal{U}]
  .\end{align*} 
\end{lemma}
\begin{exercise}
 Proof the above Lemma 
\end{exercise}
\subsection{Stochastic Processes And Brownian Motion}
\begin{definition}[Stochastic Process]
 A stochastic process is a parameterized collection of random variables 
 \begin{align*}
   X \ : \ [0,T] \times \Omega \rightarrow \R^d\ : \ \ (t,\omega ) \mapsto X(t,\omega )
 .\end{align*}
 For $  \omega  \in  \Omega $, the map 
 \begin{align*}
   X(*,\omega ) \ : \ [0,T] \to \mathbb{R}^{d}  \ : \ t \mapsto X(t,\omega )
 .\end{align*}
 is called sample path.
\end{definition}
\begin{definition}[Modification and Indistinguishable]
 Let $X(*)$  and $Y(*)$ be two stochastic processes, then we say they are modifications of each other if 
 \begin{align*}
   \P(X(t) = Y(t))  = 1 \qquad \forall t \in [0,T] 
 .\end{align*}
 We say that they are indistinguishable if 
 \begin{align*}
   \P(X(t) = Y(t) \ \forall  t \in  [0,T])  = 1 
 .\end{align*}
\end{definition}
\begin{remark}
 Note that if two stochastic processes are indistinguishable then they are also always a modification of each other,
 the reverse is not always true.
\end{remark}
\begin{definition}[History]
 Let $X(t)$ be a real valued process. The $\sigma-$algebra 
 \begin{align*}
  \mathcal{U}(t) \coloneqq  \mathcal{U}(X(s) \ | \ 0\le s\le t)
 .\end{align*}
 is called the history of $X$ until time $t\ge 0$.
\end{definition}
\begin{definition}[Martingale]
  Let $X(t)$ be a real valued process and $\E[\abs{X(t)}] < \infty$  for $\forall t \ge 0$
  \begin{enumerate}
    \item If $X(s) = \E[X(t)|\mathcal{U}(s)]$ a.s. $\forall  t \ge  s \ge  0$,  then $X(*)$ is called a martingale
    \item If $X(s) \lesseqqgtr  \E[X(t)|\mathcal{U}(s)]$ a.s. $\forall  t \ge  s \ge  0$,  then $X(*)$ is called a (super) sub-martingale
  \end{enumerate}
\end{definition}
\begin{lemma}
  Suppose $X(*)$ is a real-valued martingale and $\phi  : \mathbb{R} \to  \mathbb{R}$ a convex function.
  If $\E[\abs{\phi(X(t))}] < \infty $ for $\forall  t\ge 0$ then $\phi(X(*))$ is a sub-martingale
\end{lemma}
We leave the proof of this lemma as an exercise. Hint: apply Jensen's inequality.
\vskip5mm
\begin{theorem}[Martingale-Inequalities]
 Assume $X(*)$  is a process with continuous sample paths a.s. 
 \begin{enumerate}
   \item If $X(*)$ is a sub-martingale then $\forall  \lambda > 0$ , $t \ge 0$ it holds 
     \begin{align*}
       \P(\max_{0\le s\le t} X(s) \ge \lambda ) \le  \frac{1}{\lambda }\E[X(t)^{+} ]
     .\end{align*}
    \item If $X(*)$ is a martingale and $1 < p < \infty$ then
      \begin{align*}
        \E[\max_{0\le s\le t} \abs{X(s) }^{p} ] \le (\frac{p}{p-1})^{p} \E[\abs{X(t)}^{p} ]
      .\end{align*}
 \end{enumerate}
\end{theorem}
\begin{proof}
 Omit 
\end{proof}
\subsection{Brownian Motion}
\begin{definition}[Brownian Motion]
 A real valued stochastic process $W(*)$ is called a Brownian motion 
 or Wiener process if 
 \begin{enumerate}
   \item $W(0) = 0$ a.s.
   \item $W(t)$ is continuous a.s.
   \item $W(t) - W(s) \sim \mathcal{N}(0,t-s)$ for $\forall t\ge s\ge 0$
   \item $\forall \ 0 < t_{1}<t_{2}<\ldots <t_n$ , $W(t_{1}),W(t_{2})-W(t_{1}),\ldots ,W(t_n)-W(t_{n-1})$ are independent 
 \end{enumerate}
\end{definition}
\begin{remark}
 One can derive directly that 
 \begin{align*}
   \E[W(t)] = 0, \quad \E[W^2(t)] = t, \quad \E[W(t)W(s)] = t\land s\qquad \forall t,s \ge 0
 .\end{align*}
\end{remark}
The first two facts are trivial from the normal distribution, the third one can obtained inthe following, for $t\ge s\geq 0$ 
\begin{align*}
  \E[W(t)W(s)] &= \E[(W(t)-W(s))(W(s))]+\E[(W(s)w(s))]\\
               &= \E[W(t)-W(s)]\E[W(s)] + \E[W(s)W(s)] = s
.\end{align*}

\begin{definition}
 An $\mathbb{R}^{d} $  valued process $W(*) = (W^{1}(*),\ldots ,W^{d}(*)  )$ is a $d-$dimensional Wiener process (or Brownian motion) if
 \begin{enumerate}
   \item $W^{k}(*) $ is a 1-$D$ Wiener process for $\forall  k =1 ,\ldots ,d$
   \item $\mathcal{U}(W^{k}(t) \ , \ t\ge 0 )$, the $\sigma-$algebras, are independent $k=1,\ldots ,d$.
 \end{enumerate}
\end{definition}
\begin{remark}
 If $W(*)$  is  a $d-$Dimensional Brownian motion, then $W(t) \sim \mathcal{N}(0,t)$ and for any Borel set $A \subset  \mathbb{R}^{d} $
 \begin{align*}
  \P(W(t) \in  A) = \frac{1}{(2\pi t)^{\frac{d}{2}} } \int_A e^{-\frac{\abs{x}^2}{2t}} dx
 .\end{align*}
\end{remark}
\begin{theorem}
 If $X(*)$  is a given stochastic process with a.s. continuous sample paths and 
 \begin{align*}
   \E[\abs{X(t)-X(s)}^{\beta } ] \le  C \abs{t-s}^{1+\alpha } 
 .\end{align*}
 Then for $0< \gamma  < \frac{\alpha }{\beta }$, $T > 0$, and a.s. $\omega$, there exists $ K = K(\omega ,\gamma ,T)$ s.t.
 \begin{align*}
  \abs{X(t,\omega )-X(s,\omega )}\le K \abs{t-s}^{\gamma } \quad \forall  0 \le s, t \le T 
 .\end{align*}
\end{theorem}
\begin{proof}
 Omit 
\end{proof}
An application of this result on Brownian motion is interesting since 
\begin{align*}
  \E[\abs{W(t)-W(s)}^{2m} ] \le  C \abs{t-s}^{m}  \mbox{ holds for all } m\in\N
.\end{align*}
we get immediately 
\begin{align*}
  W(*,\omega ) \in  \mathcal{C}^{\gamma }([0,T])  \quad 0<\gamma <\frac{m-1}{2m} < \frac{1}{2}, \forall  m \gg 1
.\end{align*}
This means that Brownian motions is a.s. path Hölder continuous up to exponent $\frac{1}{2}$.
\begin{remark}
  One can also further prove that the path wise smoothness  of Brownian motion can not be better than Hölder  continuous. Namely 
  \begin{enumerate}
    \item $\forall  \gamma  \in  (\frac{1}{2},1]$  and a.s. $\omega , t \mapsto W(t,\omega )$ is nowhere Hölder  continuous with exponent $\gamma $
    \item $\forall $ a.s. $\omega  \in  \Omega $ the map $t \mapsto W(t,\omega )$ is nowhere differentiable and is of infinite variation on each subinterval.
  \end{enumerate}
\end{remark}
\begin{definition}[Markov Property]
 An $\mathbb{R}^{d}-$valued process $X(*)$ is said to have the Markov property, if $\forall  0\le s\le t$ and 
 $\forall B \subset  \mathbb{R}^{d} $ Borel set, it holds 
 \begin{align*}
   \P(X(t) \in  B | \mathcal{U}(s)) = \P(X(t) \in  B | X(s)) \text{ a.s.}
 .\end{align*}
\end{definition}
\begin{remark}
 The $d-$Dimensional Wiener Process $W(*)$  has Markov property and it holds almost surely that 
 \begin{align*}
  \P(W(t)\in B | W(s)) = \frac{1}{(2\pi(t-s))^{\frac{n}{2}} } \int_B e^{-\frac{\abs{x - W(s)}^2}{2(t-s)}}  dx
 .\end{align*}
\end{remark}
\subsection{Convergence of Measure and Random Variables}
In the following we include a couple of definitions for the convergence of measures and random variables
\begin{theorem}[Weak convergence of measures]
 The following statements are equivalent   
 \begin{enumerate}
   \item $\mu_n \rightharpoonup \mu $
   \item For $\forall  f \in  \mathcal{C}_b(\mathbb{R}^{d} )$ it holds $ \int f d\mu_n \to \int  f d\mu$.
\item For $\forall  B \in \mathcal{B} $, it holds $   \mu_n(B) \to  \mu(B)$.
\item For $\forall f \in  \mathcal{C}_b(\mathbb{R}^{d} )$ uniform continuous it holds 
$   \int  f d\mu_n \to  \int f d\mu $.
 \end{enumerate}
\end{theorem}
\begin{theorem}[Weak convergence of Random variable]
 The following statements are equivalent  
 \begin{enumerate}
   \item $X_n$ converges weakly in Law to $X$, i.e. $ X_n \rightharpoonup X$.
   \item For $\forall f \in  \mathcal{C}_b(\mathbb{R}^{d} )$ it holds $\E[f(X_n)] \to \E[f(x)]$.
 \end{enumerate}
 \end{theorem}
\begin{exercise}
 Prove that 
 \begin{align*}
   X_n \to  X \ \text{a.s.} \implies \P(\abs{X_n - X} > \epsilon ) \xrightarrow{n\to \infty} 0 \implies X_n \rightharpoonup X
 .\end{align*}
\end{exercise}
\begin{definition}[Tightness]
 A set of probability measures $S \subset  \mathcal{P}(\mathbb{R}^{d} )$  is called tight, if 
 for $\forall \ \epsilon  > 0$ there exists $\exists \  K \subset  \mathbb{R}^{d} $ compact such that 
 \begin{align*}
   \sup_{\mu  \in  S} \mu(K^{c} )  \le  \epsilon 
 .\end{align*}
\end{definition}
\begin{theorem}[Prokhorov's theorem]
  A sequence of measures $(\mu_n)_{n \in  \mathbb{N}}$  is tight in $\mathcal{P}(\mathbb{R}^{d} )$ iff 
  any subsequence has a weakly convergences subsequence.
\end{theorem}
\begin{proof}
 Refer to literature 
\end{proof}

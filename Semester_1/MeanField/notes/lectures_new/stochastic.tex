\chapter{MEAN FIELD LIMIT FOR SDE SYSTEM}
\section{Basics On Probability Theory}
This section is dedicated to a small review of basic concepts 
in probability theory in preparations of SDE's
\subsection{Probability Spaces and Random Variables}
\begin{definition}[$\sigma$-Algebra]
 Let $\Omega $  be a given set, then a $\sigma-$algebra $\mathcal{F}$ on $\Omega $ is a
 family of subsets of $\Omega $ s.t.
 \begin{enumerate}
   \item $\emptyset \in  \mathcal{F}$
   \item $F \in  \mathcal{F} \implies F^{c} \in  \mathcal{F} $
   \item If $A_{1},A_{2},\ldots \in \mathcal{F}$ countable, then 
     \begin{align*}
       A = \bigcup_{j=1}^{\infty} A_j \in \mathcal{F}
     .\end{align*}
 \end{enumerate}
\end{definition}
\begin{definition}[Measure Space]
 A tuple $(\Omega ,\mathcal{F})$  is called a measurable space. The elements of $\mathcal{F}$ are 
 called measurable sets 
\end{definition}
\begin{definition}[Probability Measure]
 A probability measure $\P$ on $(\Omega ,\mathcal{F})$  is a function 
 \begin{align*}
   \P \ : \ \mathcal{F} \to [0,1]
 .\end{align*}
 s.t.
 \begin{enumerate}
   \item $\P(\emptyset) = 0$ , $\P(\Omega ) = 1$
   \item If $A_{1},A_{2},\ldots \in \mathcal{F}$ s.t. $A_i \cap A_j = \emptyset \ \forall  i \neq j$  then
     \begin{align*}
       \P(\bigcup_{j=1}^{\infty} A_j ) = \sum_{j=1}^{\infty} \P(A_j) 
     .\end{align*}
 \end{enumerate}
\end{definition}
\begin{definition}[Probability Space]
 The triple $(\Omega ,\mathcal{F},\P)$  is called a probability space. $F \in  \mathcal{F}$ is called
 event. We say the probability space $(\Omega ,\mathcal{F},\P)$ is complete, if $\mathcal{F}$ contains all zero-measure sets i.e.
 if 
 \begin{align*}
  \inf \{\P(F) \ : \ F \in  \mathcal{F},G \subset  F\}  = 0
 .\end{align*}
 then $G \in  \mathcal{F}$ and $\P(G) = 0$. Without loss of generality we use in this lecture $(\Omega ,\mathcal{F},\P)$
 as complete probability space
\end{definition}
\begin{definition}[Almost Surely]
  If for some $F \in  \mathcal{F}$ it holds $\P(F) = 1$ the we say that $F$ happens with 
  probability 1 or almost surely (a.s.)
\end{definition}
\begin{remark}
 Let $\mathcal{H}$  be a family of subsets of $\Omega$, then there exists a smallest $\sigma-$algebra of 
 $\Omega$ called $\mathcal{U}_{\mathcal{H}}$ with 
 \begin{align*}
   \mathcal{U}_{\mathcal{H}} = \bigcap_{\substack{\mathcal{H} \subset \mathcal{U} \\ \mathcal{H} \ \sigma-\text{alg.}}} \mathcal{H}  
 .\end{align*}
\end{remark}
\begin{example}
  The $\sigma-$algebra generated by a topology $\tau $ of $\Omega$ , $\mathcal{U}_{\tau } \triangleq \mathcal{B}$ is called 
  the Borel $\sigma-$algebra, the elements $B \in  \mathcal{B}$ are called Borel sets.
\end{example}
\begin{definition}[Measurable Functions]
 Let $(\Omega ,\mathcal{F},\P)$  be a probability space, a function 
 \begin{align*}
  Y \ : \ \Omega  \to \mathbb{R}^{d} 
 .\end{align*}
 is called measurable if and only if 
 \begin{align*}
  Y^{-1}(B) \in  \mathcal{F} 
 .\end{align*}
 holds for all $B \in  \mathcal{B}$ or equivalent for all $B \in  \tau $
\end{definition}
\begin{example}
 Let $X : \Omega  \to  \mathbb{R}^{d} $  be a given function, then the $\sigma-$algebra $\mathcal{U}(X)$ generated by X is 
 \begin{align*}
  \mathcal{U}(X) = \{X^{-1}(B) \ : \ B \in  \mathcal{B} \}  
 .\end{align*}
\end{example}
\begin{lemma}[Doob-Dynkin]
 If $X,Y \ : \ \Omega  \to \mathbb{R}^{d} $  are given then $Y$ is $\mathcal{U}(X)$ measurable if and only if 
 there exists a Boreal measurable function $g \ : \ \mathbb{R}^{d} \to  \mathbb{R}^{d}  $ such that 
 \begin{align*}
  Y = g(x)
 .\end{align*}
\end{lemma}
\begin{exercise}
  Proof the above lemma
\end{exercise}
From now on we denote $(\Omega ,\mathcal{F},\P)$ as a given probability space.
\begin{definition}[Random Variable]
 A random variable $X \ : \ \Omega  \to \mathbb{R}^{d} $  is a $\mathcal{F}-$measurable function.
 Every random variable induces a probability measure or $\mathbb{R}^{d} $ 
 \begin{align*}
  \mu_X(B) = \P(X^{-1}(B) ) \quad \forall B \in  \mathcal{B}
 .\end{align*}
This measure is called the distribution of X
\end{definition}
\begin{definition}[Expectation and Variance]
 Let $X$ be a random variable, if 
 \begin{align*}
   \int_{\Omega } \abs{X(\omega )}d\P(\omega ) < \infty
 .\end{align*}
 then 
 \begin{align*}
   \E[X] = \int_{\Omega } X(\omega ) d\P(\omega ) =  \int_{\mathbb{R}^{d} }x d\mu_X(x)
 .\end{align*}
 is called the expectation of $X$ (w.r.t. $\P$) \\[1ex]
 \begin{align*}
   \V[X] = \int_{\Omega } \abs{X - \E[X]}^2 d\P(\omega )
 .\end{align*}
 is called variance and there exists the simple relation 
 \begin{align*}
   \V[X] = \E[\abs{X-\E[X]}^2] = \E[\abs{X}^2] - \E[X]^2
 .\end{align*}
\end{definition}
\begin{remark}
 If $f : \mathbb{R}^{d} \to  \mathbb{R} $ measurable and 
 \begin{align*}
   \int_{\Omega } \abs{f(X(\omega ))} d\P(\Omega ) <\infty
 .\end{align*}
 then 
 \begin{align*}
   \E[f(x)] = \int_{\Omega }f(X(\omega ))d\P(\omega ) = \int_{\mathbb{R}^{d} }f(x) d\mu_X(x)
 .\end{align*}
\end{remark}
\begin{definition}[$L^p$ spaces]
  Let $X : \Omega  \to  \mathbb{R}^{d} $  be a random variable and $p \in [1,\infty)$.
  With the norm 
  \begin{align*}
    \|X\|_p = \|X\|_{L^{p}(\P ) } = \left( \int_{\Omega} \abs{X(\omega )}^{p} d\P(\omega )  \right)^{\frac{1}{p}} 
  .\end{align*}
  If $p=\infty$ 
  \begin{align*}
    \|X\|_{\infty} = \inf \{N \in  \mathbb{R} : \abs{X(\omega )} \le  N \text{ a.s.}\}  
  .\end{align*}
  the space $L^{p}(\P ) = L^{p}(\Omega ) = \{X \ : \ \Omega  \to  \mathbb{R}^{d}  \ | \ \|X\|_p \le \infty \}    $ is a Banach space.
\end{definition}
\begin{remark}
 If $p=2$ then $L^{2}(\P) $ is a Hilbert space with inner product 
 \begin{align*}
   \braket{X,Y} = \E[X(\omega )*Y(\Omega )] = \int_{\Omega }X(\omega )*Y(\omega )d\P(\omega )
 .\end{align*}
\end{remark}
\begin{definition}[Distribution Functions]
 Note for $x,y \in  \mathbb{R}^{d} $  we write $x\le y$ if $x_i \le  y_i$ for $\forall i$
 \begin{enumerate}
   \item $X: (\Omega ,\mathcal{F},\P) \to \mathbb{R}^{d} $ is a random variable the ints distribution function $F_x : \mathbb{R}^{d} \to [0,1] $
     is defined by 
     \begin{align*}
      F_X(x) = \P(X\le x) \quad x \in  \mathbb{R}^{d} 
     .\end{align*}
    \item If $X_{1},\ldots ,X_m : \Omega \to \mathbb{R}^{d} $ are random variables, their joint distribution function is
      \begin{align*}
        F_{X_{1},\ldots ,X_m} &: (\mathbb{R}^{d} )^m \to [0,1]\\
        F_{X_{1},\ldots ,X_M} &= \P(X_{1}\le x_{1},\ldots ,X_m\le x_m) \quad \forall x_i \in \mathbb{R}^{d} 
      .\end{align*}
 \end{enumerate}
\end{definition}
\begin{definition}[Density Function Of X]
 If there exists a non-negative function $f(x) \in  L^{1}(\mathbb{R}^{d} ; \mathbb{R} ) $   such that 
 \begin{align*}
   F(x) = \int_{-\infty}^{x_{1}}  \ldots \int_{-\infty}^{x_n} f(y) dy \quad y = (y_{1},\ldots ,y_n)
 .\end{align*}
 then f is called density function of $X$ and 
 \begin{align*}
  \P(X^{-1}(B) ) = \int_B f(x) dx \quad \forall  B \in  \mathcal{B}
 .\end{align*}
\end{definition}
\begin{example}
 Let $X$ be random variable with density function  $x \in  \mathbb{R}$
 \begin{align*}
  f(x) = \frac{1}{\sqrt{2\pi \sigma ^2}e^{-\frac{\abs{x-m}^2}{2\sigma ^2}}  }
 .\end{align*}
 then we say that $X$ has a Gaussian (or Normal) distribution with mean m and variance $\sigma^2$ and write
 \begin{align*}
  X \sim \mathcal{N}(m,\sigma^2)
 .\end{align*}
 Obviously 
 \begin{align*}
   \int_{\mathbb{R}} xf(x) dx = m \qquad \int_{\mathbb{R}}\abs{x-m}^2f(x) dx = \sigma^2
  .\end{align*}
\end{example}
\begin{definition}[Independent Events]
  Events $A_{1},\ldots ,A_{n} \in  \mathcal{F}$ are called independent if $\forall 1 \le k_{1} < \ldots  < k_m \le  n$ it holds 
  \begin{align*}
    \P(A_{k_{1}}\cap A_{k_2} \cap \ldots \cap A_{k_m} )=\P(A_{k_{1}})\P(A_{k_{2}})\ldots \P(A_{k_m})
  .\end{align*}
\end{definition}
\begin{definition}[Independent $\sigma-$Algebra]
 Let $\mathcal{F}_j \subset  \mathcal{F}$   be $\sigma-$algebras for $j=1,2,\ldots $. Then we say $\mathcal{F}_j$ are independent if 
 for $\forall 1 \le k_{1}<k_{2}<\ldots <k_m$ and $\forall A_{k_j} \in  \mathcal{F}_{k_j}$ it holds
 \begin{align*}
  \P(A_{k_{1}}\cap A_{k_2} \cap \ldots \cap A_{k_m} )=\P(A_{k_{1}})\P(A_{k_{2}})\ldots \P(A_{k_m})
 .\end{align*}
\end{definition}
\begin{definition}[Independent Random Variables]
 We say random variables $X_{1},\ldots ,X_m \ : \ \Omega  \to \mathbb{R}^{d} $  are independent if 
 for $\forall  B_{1},\ldots ,B_{m} \subset  \mathcal{B}$ in $\mathbb{R}^{d} $ it holds 
 \begin{align*}
   \P(X_{j_{1}}\in B_{j_{1}},\ldots, X_{j_k}\in B_{j_k} ) = \P(X_{j_{1}} \in  B_{j_{1}})\ldots \P(X_{j_k} \in  B_{j_k})
 .\end{align*}
 which is equivalent to proving that $\mathcal{U}(X_{1}),\ldots ,\mathcal{U}(X_k)$ are independent
\end{definition}
\begin{theorem}
 $X_{1},\ldots ,X_m \ : \ \Omega  \to \mathbb{R}^{d} $ are independent if and only if 
 \begin{align*}
   F_{X_{1},\ldots ,X_m}(x_{1},\ldots ,x_m) =F_{X_{1}}(x_{1})\ldots F_{x_m}(x_m) \quad \forall  x_i \in \mathbb{R}^{d} 
 .\end{align*}
\end{theorem}
\newpage
\begin{theorem}
  If $X_{1},\ldots ,X_m \ : \ \Omega  \to \mathbb{R} $ are independent and $\E[\abs{X_i}] < \infty$ then 
  \begin{align*}
    \E[\abs{X_{1},\ldots ,X_m}]<\infty
  .\end{align*}
  and 
  \begin{align*}
    \E[X_{1}\ldots X_m] = \E[X_{1}]\ldots \E[X_m]
  .\end{align*}
\end{theorem}
\begin{theorem}
  $X_{1},\ldots ,X_m \ : \ \Omega  \to \mathbb{R} $ are independent and $\V[X_i] <\infty$ then 
  \begin{align*}
    \V[X_{1} + \ldots  + X_m] = \V[X_{1}] + \ldots  + \V[X_m]
  .\end{align*}
\end{theorem}
\begin{exercise}
 Proof the above theorems
\end{exercise}
\subsection{Borel Cantelli}
\begin{definition}
 Let $A_{1},\ldots ,A_m \in \mathcal{F}$   then the set 
 \begin{align*}
   \bigcap_{n=1}^{\infty}\bigcup_{m=n}^{\infty} A_m = \{\omega \in \Omega  \ : \ \omega  \text{ belongs to infinite many} A_{m}\text{'s}\}  
 .\end{align*}
 is called $A_m$ infinitely often or $A_m$ i.o.
\end{definition}
\begin{lemma}[Borel Cantelli]\label{borel_cantelli}
 If $\sum_{m=1}^{\infty} \P(A_m) < \infty  $  then $\P(A_ \text{ i.o. }) = 0$
\end{lemma}
\begin{proof}
 By definition we have 
 \begin{align*}
   \P(A_m \text{ i.o. }) \le  \P(\bigcup_{m=n}^{\infty} ) \le \sum_{m=n}^{\infty} \P(A_m)  \xrightarrow{m\to \infty} 0
 .\end{align*}
\end{proof}
\begin{definition}[Convergence In Probability]
  We say a sequence of random variables $(X_k)_{k=1}^{\infty} $  converges in probability to $X$ if 
  for $\forall  \epsilon > 0$
  \begin{align*}
    \lim_{k\to \infty} \P(\abs{X_k - X} > \epsilon ) = 0 
  .\end{align*}
\end{definition}
\begin{theorem}[Application Of Borel Cantelli]
 If $X_k \to  X$  in probability, then there exists 
 a subsequence $(X_{k_j})_{j=1}^{\infty} $ such that 
 \begin{align*}
   X_{k_j}(\omega ) \to X(\omega ) \text{ for almost every } \omega \in  \Omega 
 .\end{align*}
 This means that $\P(\abs{X_{k_j}-X}\to 0) = 1$
\end{theorem}
\begin{proof}
  For $\forall  j \ \exists k_j$  with $k_j < k_{j+1} \to  \infty$ s.t.
  \begin{align*}
    \P(\abs{X_{k_j} - X} > \frac{1}{j}) \le \frac{1}{j^2}
  .\end{align*}
  then 
  \begin{align*}
    \sum_{j=1}^{\infty} \P(\abs{X_{k_j}-X} > \frac{1}{j}) = \sum_{j=1}^{\infty} \frac{1}{j^2}   < \infty
  .\end{align*}
  Let $A_j = \{\omega  \ : \ \abs{X_{k_j}-X} > \frac{1}{j}\}  $ then by \nameref{borel_cantelli} we have $\P(A_j\text{ i.o.}) = 0$ s.t.
  \begin{align*}
    \forall  \omega  \in  \Omega  \ \exists J \text{ s.t. } \forall  j>J
  .\end{align*}
  it holds 
  \begin{align*}
    \abs{X_{k_j}(\omega ) - X(\omega )} \le  \frac{1}{j}
  .\end{align*}
\end{proof}
\subsection{Strong Law Of Large Numbers}
\begin{definition}
 A sequence of random variables $X_{1},\ldots ,X_n$  is called identically distributed if 
 \begin{align*}
   F_{X_{1}}(x)= F_{X_{2}}(x) = \ldots  = F_{X_n}(x) \quad \forall x \in  \mathbb{R}^{d}  
 .\end{align*}
 If additionally $X_{1},\ldots ,X_n$ are independent then we say they are identically-independent-distributed i.i.d
\end{definition}
\begin{theorem}[Strong Law Of Large Numbers]
 Let $X_{1},\ldots ,X_N$  be a sequence of i.i.d integrable random variables on the same probability
 space $(\Omega ,\mathcal{F},\P)$ then 
 \begin{align*}
   \P(\lim_{N \to  \infty} \frac{X_1 + \ldots  + X_N}{N} = \E[X_i]) = 1
 .\end{align*}
 where $\E[X_i] = \E[X_j]$ 
\end{theorem}
\begin{proof}
  Suppose for simplicity $\E[X^{4} ] < \infty$  for $\forall  i = 1,2,\ldots $.
  Then without loss of generality we may assume $\E[X_i] = 0$ otherwise we use $X_i - \E[X_i]$ as our new sequence.
  Consider 
  \begin{align*}
    \E[(\sum_{i=1}^{N} X_i )^{4} ] = \sum_{i,j,k,l}\E[X_iX_jX_kX_l]
  .\end{align*}
  If $i \neq j ,k,l$ then because of independence it follows that 
  \begin{align*}
    \E[X_iX_jX_kX_l] = \E[X_i]\E[X_jX_kX_l] = 0
  .\end{align*}
  Then 
  \begin{align*}
    \E[(\sum_{i=1}^{N}X_i )^{4} ] &= \sum_{i=1}^{N}\E[X_i^{4} ]  + 3 \sum_{i\neq j}\E[X_i^2X_j^2] \\
                                  &= N\E[X_{1}^{4} ] + 3(N^2-N)\E[X_{1}^2]^2 \\
                                  &\le  N^2C
  .\end{align*}
  Therefore for fixed $\epsilon > 0$
  \begin{align*}
    \P(\abs{\frac{1}{N} \sum_{i=1}^{N}X_i } \ge \epsilon) &= \P(\abs{\sum_{i=1}^{N}X_i }^{4}  \ge (\epsilon N)^{4} )\\
                                                          &\myS{Mrkv.}{\le} \frac{1}{(\epsilon N)^{4} } \E[\abs{\sum_{i=1}^{N} X_i }^{4} ]\\
                                                          &\le  \frac{C}{\epsilon^4}\frac{1}{N^2}
  .\end{align*}
  Then by \nameref{borel_cantelli} we get 
  \begin{align*}
    \P(\abs{\frac{1}{N} \sum_{i=1}^{N} X_i } \ge  \epsilon \text{ i.o.}) = 0
  .\end{align*}
  because 
  \begin{align*}
    \sum_{N=1}^{\infty} \P(A_N)  = \sum_{N=1}^{\infty} \frac{C}{\epsilon^4}\frac{1}{N^2}  < \infty
  .\end{align*}
  where  
  \begin{align*}
    A_N = \{\omega  \in  \Omega  \ : \ \abs{\frac{1}{N}\sum_{i=1}^{N}X_i } \ge  \epsilon\}  
  .\end{align*}
  Now we take $\epsilon = \frac{1}{k}$ then the above gives 
  \begin{align*}
    \lim_{N\to \infty} \sup \frac{1}{N} \sum_{i=1}^{N}  X_i(\omega ) \le \frac{1}{k}
  .\end{align*}
  holds except for $\omega  \in  B_k$ with $\P(B_k) = 0$. Let $B = \bigcup_{k=1}^{\infty} B_k $ then $\P(B) = 0$ and
  \begin{align*}
    \lim_{N \to \infty} \frac{1}{N} \sum_{i=1}^{N} X_i(\omega ) = 0  \text{ a.e.}
  .\end{align*}
\end{proof}
\subsection{Conditional Expectation}
\begin{definition}
  Let $Y$ be random variable, then $\E[X|  Y] $ is defined as a $\mathcal{U}(Y)-$measurable random variable
  s.t for $\forall  A \in \mathcal{U}(Y)$ it holds 
  \begin{align*}
    \int_A X d\P = \int_A \E[X|Y] d\P
  .\end{align*}
\end{definition}
\begin{definition}
 Let $(\Omega ,\mathcal{F},\P)$  be a probability space and $\mathcal{ U} \subset  \mathcal{F}$ be a $\sigma-$algebra,
 if $X  : \Omega  \to  \mathbb{R}^{d} $ is an integrable random variable then $\E[X |\mathcal{U}]$  is
 defined as a random variable on $\Omega$ s.t. $\E[X | \mathcal{U}]$ is $\mathcal{U}-$measurable and for $\forall A \in  \mathcal{U}$
 \begin{align*}
   \int_A X d\P  = \int_A \E[X | \mathcal{U}] d \P
 .\end{align*}
\end{definition}
\begin{exercise}
 Proof the following equalities  
 \begin{enumerate}
   \item $\E[X|Y] = \E[X | \mathcal{U}]$
   \item $\E[\E[X|\mathcal{U}]] = \E[X]$
   \item $\E[X] = \E[X | \mathcal{W}]$, where $\mathcal{W} = \{\emptyset,\Omega \}  $
 \end{enumerate}
\end{exercise}
\begin{remark}
 One can define the conditional probability similarly. Let $\mathcal{V} \subset  \mathcal{U}$  be a $\sigma-$algebra 
 then for $A \in  \mathcal{U}$ the conditional probability is defined as follows
 \begin{align*}
   \P(A | \mathcal{V}) = \E[\cha_A | \mathcal{V}]
 .\end{align*}
Note the equivalent notation $\chi_A \equiv \cha_A$
\end{remark}
\begin{theorem}
 Let $X$ be an integrable random variable, then for all $\sigma-$algebras $\mathcal{U} \subset  \mathcal{F}$  the 
 conditional expectation $\E[X | \mathcal{U}]$ exists and is unique up to $\mathcal{U}-$measurable sets of probability
 zero
\end{theorem}
\begin{proof}
 Omit 
\end{proof}
\begin{theorem}[Properties Of Conditional Expectation]
 \begin{enumerate}
   \item If $X$ is $\mathcal{U}-$measurable then $\E[X|\mathcal{U}] = X$ a.s.
   \item $\E[aX + bY|\mathcal{U}] = a\E[X|\mathcal{U}] + b \E[Y|\mathcal{Y}]$
   \item If $X$ is $\mathcal{U}-$measurable and $XY$ is integrable then 
     \begin{align*}
       \E[XY|\mathcal{U}] = X \E[Y|\mathcal{Y}]
     .\end{align*}
   \item If $X$ is independent of $\mathcal{U}$ then $\E[X|\mathcal{U}] = \E[X]$ a.s.
   \item If $\mathcal{W} \subset  \mathcal{U}$ are two $\sigma-$algebras then 
     \begin{align*}
       \E[X|\mathcal{W}] = \E[\E[X|\mathcal{U}]|\mathcal{W}] = \E[\E[X|\mathcal{W}]|\mathcal{U}] \text{ a.s.}
     .\end{align*}
   \item If $X\le Y$ a.s. then $\E[X|\mathcal{U}] \le \E[Y\mathcal{U}]$  a.s.
 \end{enumerate} 
\end{theorem}
\begin{exercise}
 Proof the above properties  
\end{exercise}
\begin{lemma}[Conditional Jensen's Inequality]
  Suppose $\phi  : \mathbb{R}\to \mathbb{R}$ is convex and $\E[\phi(x)] < \infty$ then
  \begin{align*}
    \phi(\E[X|\mathcal{U}]) \le \E[\phi(X)|\mathcal{U}]
  .\end{align*} 
\end{lemma}
\begin{exercise}
 Proof the above Lemma 
\end{exercise}
\subsection{Stochastic Processes And Brownian Motion}
\begin{definition}[Stochastic Process]
 A stochastic process is a parameterized collection of random variables 
 \begin{align*}
   (X(t))_{t \in [0,T]} \ : [0,T] \times \Omega  \ : \ \ (t,\omega ) \mapsto X(t,\omega )
 .\end{align*}
 For $\forall  \omega  \in  \Omega $ the map 
 \begin{align*}
   X(*,\omega ) \ : \ [0,T] \to \mathbb{R}^{d}  \ : \ t \mapsto X(t,\omega )
 .\end{align*}
 is called sample path
\end{definition}
\begin{definition}[History]
 Let $X(t)$ be a real valued process. The $\sigma-$algebra 
 \begin{align*}
  \mathcal{U}(t) \coloneqq  \mathcal{U}(X(s) \ | \ 0\le s\le t)
 .\end{align*}
 is called the history of $X$ until time $t\ge 0$
\end{definition}
\begin{definition}[Martingale]
  Let $X(t)$ be a real valued process and $\E[\abs{X(t)}] < \infty$  for $\forall t \ge 0$
  \begin{enumerate}
    \item If $X(s) = \E[X(t)|\mathcal{U}(s)]$ a.s. $\forall  t \ge  s \ge  0$  then $X(*)$ is called a martingale
    \item If $X(s) \lesseqqgtr  \E[X(t)|\mathcal{U}(s)]$ a.s. $\forall  t \ge  s \ge  0$  then $X(*)$ is called a (super) sub-martingale
  \end{enumerate}
\end{definition}
\begin{lemma}
  Suppose $X(*)$ is a real-valued martingale and $\phi  : \mathbb{R} \to  \mathbb{R}$ a convex function.
  If $\E[\abs{\phi(X(t))}] < \infty $ for $\forall  t\ge 0$ then $\phi(X(*))$ is a sub-martingale
\end{lemma}
\begin{theorem}[Martingale-Inequalities]
 Assume $X(*)$  is a process with continuous sample paths a.s. 
 \begin{enumerate}
   \item If $X(*)$ is a sub-martingale then $\forall  \lambda > 0$ , $t \ge 0$ it holds 
     \begin{align*}
       \P(\max_{0\le s\le t} X(s) \ge \lambda ) \le  \frac{1}{\lambda }\E[X(t)^{+} ]
     .\end{align*}
    \item If $X(*)$ is a martingale and $1 < p < \infty$ then
      \begin{align*}
        \E[\max_{0\le s\le t} \abs{X(s) }^{p} ] \le (\frac{p}{p-1})^{p} \E[\abs{X(t)}^{p} ]
      .\end{align*}
 \end{enumerate}
\end{theorem}
\begin{proof}
 Omit 
\end{proof}
\subsection{Brownian Motion}
\begin{definition}[Brownian Motion]
 A real valued stochastic process $W(*)$ is called a Brownian motion 
 or Wiener process if 
 \begin{enumerate}
   \item $W(0) = 0$ a.s.
   \item $W(t)$ is continuous a.s.
   \item $W(t) - W(s) \sim \mathcal{N}(0,t-s)$ for $\forall t\ge s\ge 0$
   \item $\forall \ 0 < t_{1}<t_{2}<\ldots <t_n$ , $W(t_{1}),W(t_{2})-W(t_{1}),\ldots ,W(t_n)-W(t_{n-1})$ are independent 
 \end{enumerate}
\end{definition}
\begin{remark}
 One can derive directly that 
 \begin{align*}
   \E[W(t)] = 0 \quad \E[W^2(t)] = t \qquad \forall t \ge 0
 .\end{align*}
\end{remark}










